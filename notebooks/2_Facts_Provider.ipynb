{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London School ORG\n",
      "National Gallery ORG\n",
      "World Heritage Sites ORG\n",
      "River Thames ORG\n",
      "Buckingham Palace ORG\n",
      "British Museum ORG\n",
      "London Assembly ORG\n",
      "Natural History Museum ORG\n",
      "Tate ORG\n",
      "Tower Bridge ORG\n",
      "British Library ORG\n",
      "Inner London ORG\n",
      "Greater London ORG\n",
      "Imperial College London ORG\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import textacy.extract\n",
    "import wikipedia\n",
    "\n",
    "# Let's assume that we detected an intent of {fact_information} or {interesting_places}\n",
    "# something like that, where users want to look for interesting things to do where they are\n",
    "\n",
    "# First, we could extract information from Wikipedia related to the city\n",
    "city_info = wikipedia.summary('London')\n",
    "\n",
    "# Second, we could use the parsing from spaCy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "doc = nlp(city_info)\n",
    "\n",
    "# Third, by using the tool textacy we can get noun_chunks that my be helpful to suggest interesting places\n",
    "noun_chunks = textacy.extract.noun_chunks(doc)\n",
    "noun_chunks = map(str, noun_chunks)\n",
    "\n",
    "# Forth, we select first those nouns greater than 2 words\n",
    "# Fifth, we process again entities to get rid of those that are not places or important \n",
    "for noun_chunk in set(noun_chunks):\n",
    "    if len(noun_chunk.split(' ')) > 1:\n",
    "        aux_doc = nlp(noun_chunk)\n",
    "        for ent in aux_doc.ents:\n",
    "            if ent.label_ in ['ORG'] and ent.text[0].isupper():\n",
    "                print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
